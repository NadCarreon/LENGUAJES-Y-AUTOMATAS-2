# Bibliografias
Bibliografias de grandes exponentes de la computacion y del software

# Charles Babbage

![220px-CharlesBabbage](https://user-images.githubusercontent.com/72422120/95419906-699f6280-0932-11eb-8b3d-d66c0b5fa989.jpg)

Charles Babbage (Teignmouth, Devonshire, Gran Bretaña, 26 de diciembre de 1791-Londres, 18 de octubre de 1871) fue un matemático y científico de la computación británico.1​ Diseñó y desarrolló una calculadora mecánica capaz de calcular tablas de funciones numéricas por el método de diferencias. También diseñó, pero nunca construyó, la analítica para ejecutar programas de tabulación o computación; por estos inventos se le considera como una de las primeras personas en concebir la idea de lo que hoy llamaríamos una computadora, por lo que se le considera como "El Padre de la computación". En el Museo de Ciencias de Londres se exhiben partes de sus mecanismos inconclusos. Parte de su cerebro conservado en formol se exhibe en el Royal College of Surgeons of England. Sitio en Londres.

# Aportaciones:

Su principal aporte computación fue desarrollo de una Calculadora mecánica  capaz de calcular las tablas de funciones numéricas por el método de las diferencias,  hay de una máquina analítica capaz de ejecutar programas de tabulación.

# Herman Hollerith

![Hollerith](https://user-images.githubusercontent.com/72422120/95419997-92275c80-0932-11eb-8a52-a97d0fa59b0e.jpg)

Herman Hollerith (Buffalo, Nueva York, 29 de febrero de 1860-Washington D. C., 17 de noviembre de 1929) fue un inventor que desarrolló un tabuladar electromagnético de tarjetas perforadas para ayudar en el resumen de la información y, más tarde, la contabilidad. Fue el fundador de la compañía de máquinas de tabulación que se fusionó (a través de adquisición de acciones) en 1911 con otras tres compañías para formar una quinta parte de la empresa, la Computing Tabulating Recording Company, más tarde llamada International Business Machines (IBM). Es considerado una de las figuras seminales en el desarrollo de procesamiento de datos. Su invención de la máquina de tarjetas perforadas de tabulación marcó el comienzo de la era de la semiautomáticas de procesamiento de datos de sistemas, y su concepto de que dominaba el paisaje durante casi un siglo. Está considerado como el primer informático, es decir el primero que logra el tratamiento automático de la información (Informática= Información + automática). También está dentro de los creadores de la primera computadora en el mundo.

# Aportaciones :

Fue un hombre que revolucionó el tratamiento a gran escala de información mediante la automatización, y por tanto el primer informático. Inventor de la máquina tabuladora y fundador de una de las empresas que se fusionaron en CRT, posteriormente renombrada como IBM.

# Alan Turing 

![Alan_Turing_Aged_16](https://user-images.githubusercontent.com/72422120/95420099-cb5fcc80-0932-11eb-82ad-428c9d5a942a.jpg)

Alan Mathison Turing, (Paddington, Londres, 23 de junio de 1912-Wilmslow, Cheshire, 7 de junio de 1954), fue un matemático, lógico, informático teórico, criptógrafo, filósofo, biólogo teórico, maratoniano y corredor de ultradistancia británico.

Es considerado uno de los padres de la ciencia de la computación y precursor de la informática moderna. Proporcionó una influyente formalización de los conceptos de algoritmo y computación: la máquina de Turing. Formuló su propia versión que hoy es ampliamente aceptada como la tesis de Church-Turing (1936).

Durante la segunda guerra mundial, trabajó en descifrar los códigos nazis, particularmente los de la máquina Enigma, y durante un tiempo fue el director de la sección Naval Enigma de Bletchley Park. Se ha estimado que su trabajo acortó la duración de esa guerra entre dos y cuatro años.6​ Tras la guerra, diseñó uno de los primeros computadores electrónicos programables digitales en el Laboratorio Nacional de Física del Reino Unido y poco tiempo después construyó otra de las primeras máquinas en la Universidad de Mánchester.

En el campo de la inteligencia artificial, es conocido sobre todo por la concepción de la prueba de Turing (1950), un criterio según el cual puede juzgarse la inteligencia de una máquina si sus respuestas en la prueba son indistinguibles de las de un ser humano.

La carrera de Turing terminó súbitamente tras ser procesado por homosexualidad en 1952. Dos años después de su condena, murió —según la versión oficial por suicidio; sin embargo, su muerte ha dado lugar a otras hipótesis, incluida la del asesinato—. El 24 de diciembre de 2013, la reina Isabel II del Reino Unido promulgó el edicto por el que se exoneró oficialmente al matemático, quedando anulados todos los cargos en su contra.

# Aportaciones:

En 1936 publicó un trabajo en el que propuso un ingenio abstracto, conocido posteriormente como máquina de Turing. La máquina de Turing es un modelo matemático que opera y lee instrucciones de una cinta y que es capaz de emular la lógica de funcionamiento de cualquier algoritmo de un computador.


# Norbert Wiener 

![descarga](https://user-images.githubusercontent.com/72422120/95420139-e6cad780-0932-11eb-81c0-29a1770261c8.jpg)


Su padre, Leo Wiener fue profesor de lenguas eslavas en la Universidad de Harvard. Norbert se educó en casa hasta los siete años, edad a la que empezó a asistir al colegio, pero durante poco tiempo. Siguió con sus estudios en casa hasta que volvió al colegio en 1903, graduándose en el instituto de Ayer en 1906.

En septiembre de 1906, a la edad de once años, ingresó en la Universidad Tufts para estudiar matemáticas. Se licenció en 1909 y entró en Harvard, en donde estudió zoología, pero en 1910 se trasladó a la Universidad Cornell para emprender estudios superiores en filosofía; sin embargo, meses después, volvió a Harvard. Wiener obtuvo el doctorado en dicha universidad en 1912, con una tesis que versaba sobre lógica matemática.

De Harvard pasó a Cambridge, Inglaterra, donde estudió con Bertrand Russell y G. H. Hardy. En 1914 estudió en Gotinga, Alemania con David Hilbert y Edmund Landau. Luego regresó a Cambridge y de ahí a los EE.UU. Entre 1915 y 1916 enseñó filosofía en Harvard y trabajó para la General Electric y la Encyclopedia Americana antes de dedicarse a trabajar en cuestiones de balística en el campo de pruebas de Aberdeen (Aberdeen Proving Ground), en Maryland. Permaneció en Maryland hasta el final de la guerra, cuando consiguió un puesto de profesor de matemáticas en el MIT.

Durante el tiempo que trabajó en el MIT hizo frecuentes viajes a Europa y es en esa época cuando entabla contacto con Leonardo Torres Quevedo y su máquina "El Ajedrecista". En 1926 se casó con Margaret Engemann y regresó a Europa con una beca Guggenheim. Pasó casi todo el tiempo en Gotinga o con Hardy en Cambridge. Trabajó en el movimiento browniano, la integral de Fourier, el problema de Dirichlet, el análisis armónico y en los teoremas tauberianos, entre otros problemas. Ganó el premio Bôcher en 1933.

# Aportaciones:

Publicó en Nueva York su Cybernetics, or Control and Communication in the Animal and the Machine (Cibernética o el control y comunicación en animales y máquinas), libro escrito en clave netamente matemática en el que propuso su teoría del control y la comunicación en máquinas y animales,
La Cibernética, nacida de la combinación de las matemáticas y la neurofisiología, se propone como la ciencia que permitirá el control de los “factores antihomeostáticos” inherentes a la Naturaleza y al funcionamiento de la sociedad.


# Claude Elwood Shannon

![ClaudeShannon_MFO3807](https://user-images.githubusercontent.com/72422120/95420221-05c96980-0933-11eb-8a11-d6df117154d4.jpg)


Claude Elwood Shannon (30 de abril de 1916 - 24 de febrero de 2001) fue un matemático, ingeniero eléctrico y criptógrafo estadounidense recordado como «el padre de la teoría de la información».

Shannon es reconocido por haber fundado el campo de la teoría de la información con la publicación Una teoría matemática de la comunicación, que supuso un hito en 1948. Es quizás igualmente conocido por haber sentado las bases de la teoría del diseño de circuitos digitales en 1937, con apenas 21 años de edad. Mientras realizaba su maestría en el Massachusetts Institute of Technology (MIT), demostró en su tesis que las aplicaciones electrónicas de álgebra booleana podrían construir cualquier relación lógico-numérica. Shannon contribuyó asimismo al campo del criptoanálisis para la defensa de Estados Unidos durante la Segunda Guerra Mundial, con trabajos sobre el descifrado de códigos y la seguridad en las telecomunicaciones.

# Aportaciones:

Empezó a trabajar sobre el problema de la eficacia de los diferentes métodos existentes de transmisión de la información, tanto mediante el flujo a través de hilos o cables como el aéreo, por medio de corrientes eléctricas fluctuantes o bien moduladas por la radiación electromagnética. Shannon orientó sus esfuerzos hacia la comprensión fundamental del problema y en 1948 desarrolló un método para expresar la información de forma cuantitativa.

# John Von Neumann

![JohnvonNeumann-LosAlamos](https://user-images.githubusercontent.com/72422120/95420313-22fe3800-0933-11eb-8734-fd20a117534b.gif)


John von Neumann (registrado al nacer como Neumann János Lajos; Budapest, Imperio austrohúngaro, 28 de diciembre de 1903-Washington, D. C., Estados Unidos, 8 de febrero de 1957) fue un matemático húngaro-estadounidense que realizó contribuciones fundamentales en física cuántica, análisis funcional, teoría de conjuntos, teoría de juegos, ciencias de la computación, economía, análisis numérico, cibernética, hidrodinámica, estadística y muchos otros campos. Se le considera uno de los matemáticos más importantes del siglo XX.

# Aportaciones:

Fue uno de los mátemáticos más importantes de la historia moderna cuyo legado incluye, entre otras aportaciones, la arquitectura de computadores y las máquinas autorreplicantes

# Gordon Moore

![300px-Gordon_E _Moore_2393](https://user-images.githubusercontent.com/72422120/95421639-b46ea980-0935-11eb-9583-5f48b8f2fec1.jpg)

Gordon Earl Moore (San Francisco 3 de enero de 1929) es cofundador de Intel y autor de la Ley de Moore (publicada en un artículo del 19 de abril de 1965 en la revista Electronics).

Nacido en San Francisco, California el 3 de enero de 1929. Recibió una licenciatura en química por la Universidad de California en Berkeley en 1950 y un doctorado en química y física en el Instituto de Tecnología de California (Caltech) en 1954. Previo a sus estudios en Berkeley, pasó sus primeros dos años de licenciatura en la Universidad Estatal de San José donde conoció a su esposa Betty.

Se unió al egresado de Caltech William Shockley en el laboratorio de semiconductores Shockley (división de Benchmark Instruments), pero se retiró junto con los "Traitorous Eight" (ocho traidores), cuando Sherman Fairchild estuvo de acuerdo en apoyarlos y crear la corporación de semiconductores Fairchild.

Fundó Intel en julio de 1968 junto a Robert Noyce, trabajando como Vicepresidente ejecutivo hasta 1975 cuando se convirtió en presidente y ejecutivo en jefe. En abril de 1979, el Dr. Moore se convirtió en miembro de la junta directiva además de ejecutivo en jefe, manteniendo ambas posiciones hasta abril de 1987, cuando dejó el puesto de ejecutivo en jefe. Actualmente colabora como miembro emérito de la junta directiva.

En 2001 Moore y su esposa donaron 600 millones de dólares a Caltech, la mayor donación jamás entregada a una institución de educación superior. Moore afirma que con esto pretendía mantener a Caltech en el liderazgo de investigación y tecnología. Fue miembro de la junta de Fideicomisarios de Caltech desde 1994 hasta el 2000 y continúa siendo un fideicomisario hasta el momento.

En el 2003 , fue elegido como miembro de la American Association for the Advancement of Science (“Asociación Estadounidense para el avance de la ciencia”).

La Biblioteca en el Centro para Ciencias Matemáticas de la Universidad de Cambridge, fue nombrado en honor a él y su esposa Betty Irene Whitaker, así como el edificio de laboratorios Moore (1996) en Caltech.

# Aportaciones:

La Ley de Moore fue escrita por el ingeniero Gordon Moore en 1965, cuando era director de los laboratorios Fairchild Semiconductor (aunque como sabréis, posteriormente fue el co-fundador de Intel). Él fue el primero en observar una tendencia en los primeros días de la microelectrónica que definiría la estrategia a seguir por todos los fabricantes de la industria en cuanto a la cadencia de integración de transistores en los circuitos integrados.

# Alonzo Church

![220px-Alonzo_Church](https://user-images.githubusercontent.com/72422120/95421673-cb150080-0935-11eb-81d6-11bf7cb6853d.jpg)


Matemático y lógico estadounidense creador de la base de la computación teórica. Nacido en la ciudad de Washington, se diplomó en 1924 y obtuvo su doctorado en 1927 en la Universidad de Princeton, donde ejerció como profesor entre 1929 y 1967.

Su obra más conocida es el desarrollo del cálculo lambda, y su trabajo de 1936 que muestra la existencia de problemas indecidibles. Este trabajo precedió el famoso trabajo de su alumno Alan Turing sobre el problema de parada que también demostró la existencia de problemas irresolubles por dispositivos mecánicos. Luego de revisar la tesis doctoral de Turing, demostraron que el cálculo lambda y la máquina de Turing utilizada para expresar el problema de parada tenían igual poder de expresión; posteriormente demostraron que una variedad de procesos mecánicos alternos para realizar cálculos tenían poder de cómputo equivalente. Como resultado se postuló la Tesis de Church-Turing.

# Aportaciones:

Creador de algunas de las bases de la Informática Teórica. Estableció el concepto de calculabilidad y su demostración de la indecidibilidad de la lógica de primer orden, conocido como Tesis de Church. Desarrolló el cálculo de conversión Lambda en 1936, que permite efectuar operaciones lógicas con variables generalizadas, demostrando la presencia de problemas indecidibles. Este resultado unido al trabajo de Turing sobre el problema de parada en la Máquina de Turing, que también demostraba la existencia de un problema irresoluble por medios mecánicos, demostraron que tenían capacidades de computo equivalentes, dando lugar a la Tesis Church-Turing. Destacan sus obras "The Calculi of Lambda-Conversion" (Cálculo de conversión Lambda) en 1941, e "Introduction to Mathematical Logic" (Introducción a la lógica matemática) en 1944.

# Noam Chomsky

![Noam-Chomsky-2010](https://user-images.githubusercontent.com/72422120/95421875-3068f180-0936-11eb-8574-b1181f09c7c5.jpg)

Avram Noam Chomsky (Filadelfia, 7 de diciembre de 1928) es un lingüista, filósofo, politólogo y activista estadounidense de origen judío. Es profesor emérito de lingüística en el Instituto Tecnológico de Massachusetts (MIT) y una de las figuras más destacadas de la lingüística del siglo xx, gracias a sus trabajos en teoría lingüística y ciencia cognitiva. También es reconocido por su activismo político, caracterizado por una fuerte crítica del capitalismo contemporáneo y de la política exterior de los Estados Unidos. Se le considera de pensamiento socialista libertario. El New York Times lo ha señalado como «el más importante de los pensadores contemporáneos».

Propuso la gramática generativa, disciplina que situó la sintaxis en el centro de la investigación lingüística. Con este paradigma, cambiaron la perspectiva, los programas y métodos de investigación en el estudio del lenguaje. Su lingüística es una teoría de la adquisición individual del lenguaje e intenta explicar las estructuras y principios más profundos del mismo. Postuló un aspecto bien definido de innatismo en la adquisición del lenguaje y la autonomía de la gramática (sobre los otros sistemas cognitivos), así como la existencia de un «órgano del lenguaje» y de una gramática universal. Se opuso con dureza al empirismo filosófico y científico y al funcionalismo, en favor del racionalismo cartesiano. Todas estas ideas chocaban frontalmente con las tradicionales de las ciencias humanas, lo que concitó múltiples adhesiones, críticas y polémicas que le han acabado convirtiendo en uno de los autores más citados.

# Aportaciones:

Propuso la gramática generativa, disciplina que situó la sintaxis en el centro de la investigación lingüística. Con este paradigma, cambiaron la perspectiva, los programas y métodos de investigación en el estudio del lenguaje. Su lingüística es una teoría de la adquisición individual del lenguaje e intenta explicar las estructuras y principios más profundos del mismo. Postuló un aspecto bien definido de innatismo en la adquisición del lenguaje y la autonomía de la gramática (sobre los otros sistemas cognitivos), así como la existencia de un «órgano del lenguaje» y de una gramática universal. Se opuso con dureza al empirismo filosófico y científico y al funcionalismo, en favor del racionalismo cartesiano. Todas estas ideas chocaban frontalmente con las tradicionales de las ciencias humanas, lo que concitó múltiples adhesiones, críticas y polémicas que le han acabado convirtiendo en uno de los autores más citados.
